{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yelp Data Challenge_NLP and Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('last_2_years_restaurant_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>categories</th>\n",
       "      <th>avg_stars</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>Delmonico Steakhouse</td>\n",
       "      <td>Steakhouses, Restaurants, Cajun/Creole</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-02-14</td>\n",
       "      <td>0</td>\n",
       "      <td>VETXTwMw6qxzOVDlXfe6Tg</td>\n",
       "      <td>5</td>\n",
       "      <td>went for dinner tonight. Amazing my husband ha...</td>\n",
       "      <td>0</td>\n",
       "      <td>ymlnR8UeFvB4FZL56tCZsA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>Delmonico Steakhouse</td>\n",
       "      <td>Steakhouses, Restaurants, Cajun/Creole</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-12-04</td>\n",
       "      <td>0</td>\n",
       "      <td>S8-8uZ7fa5YbjnEtaW15ng</td>\n",
       "      <td>5</td>\n",
       "      <td>This was an amazing dinning experience! ORDER ...</td>\n",
       "      <td>0</td>\n",
       "      <td>9pSSL6X6lFpY3FCRLEH3og</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>Delmonico Steakhouse</td>\n",
       "      <td>Steakhouses, Restaurants, Cajun/Creole</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-09-13</td>\n",
       "      <td>0</td>\n",
       "      <td>N1Z93BthdJ7FT2p5S22jIA</td>\n",
       "      <td>3</td>\n",
       "      <td>Went for a nice anniversary dinner. Researched...</td>\n",
       "      <td>0</td>\n",
       "      <td>CEtidlXNyQzgJSdF1ubPFw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>Delmonico Steakhouse</td>\n",
       "      <td>Steakhouses, Restaurants, Cajun/Creole</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-05-20</td>\n",
       "      <td>0</td>\n",
       "      <td>Pnkrj90xfykhHyo4BSFRsw</td>\n",
       "      <td>5</td>\n",
       "      <td>ABSOLUTE MUST IN VEGAS! Loved everything my bo...</td>\n",
       "      <td>0</td>\n",
       "      <td>cZVQGCZ_fHtTdfiyGVJPdg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>Delmonico Steakhouse</td>\n",
       "      <td>Steakhouses, Restaurants, Cajun/Creole</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-12-30</td>\n",
       "      <td>0</td>\n",
       "      <td>Oeh7e6U2xaDQI9L9i4x_Gw</td>\n",
       "      <td>2</td>\n",
       "      <td>I had high hopes for Delmonico's Steakhouse in...</td>\n",
       "      <td>0</td>\n",
       "      <td>li2cBZl60vgqihDJJG7jeA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                  name  \\\n",
       "0  --9e1ONYQuAa-CB_Rrw7Tw  Delmonico Steakhouse   \n",
       "1  --9e1ONYQuAa-CB_Rrw7Tw  Delmonico Steakhouse   \n",
       "2  --9e1ONYQuAa-CB_Rrw7Tw  Delmonico Steakhouse   \n",
       "3  --9e1ONYQuAa-CB_Rrw7Tw  Delmonico Steakhouse   \n",
       "4  --9e1ONYQuAa-CB_Rrw7Tw  Delmonico Steakhouse   \n",
       "\n",
       "                               categories  avg_stars  cool        date  funny  \\\n",
       "0  Steakhouses, Restaurants, Cajun/Creole        4.0     0  2017-02-14      0   \n",
       "1  Steakhouses, Restaurants, Cajun/Creole        4.0     0  2017-12-04      0   \n",
       "2  Steakhouses, Restaurants, Cajun/Creole        4.0     0  2016-09-13      0   \n",
       "3  Steakhouses, Restaurants, Cajun/Creole        4.0     0  2017-05-20      0   \n",
       "4  Steakhouses, Restaurants, Cajun/Creole        4.0     0  2017-12-30      0   \n",
       "\n",
       "                review_id  stars  \\\n",
       "0  VETXTwMw6qxzOVDlXfe6Tg      5   \n",
       "1  S8-8uZ7fa5YbjnEtaW15ng      5   \n",
       "2  N1Z93BthdJ7FT2p5S22jIA      3   \n",
       "3  Pnkrj90xfykhHyo4BSFRsw      5   \n",
       "4  Oeh7e6U2xaDQI9L9i4x_Gw      2   \n",
       "\n",
       "                                                text  useful  \\\n",
       "0  went for dinner tonight. Amazing my husband ha...       0   \n",
       "1  This was an amazing dinning experience! ORDER ...       0   \n",
       "2  Went for a nice anniversary dinner. Researched...       0   \n",
       "3  ABSOLUTE MUST IN VEGAS! Loved everything my bo...       0   \n",
       "4  I had high hopes for Delmonico's Steakhouse in...       0   \n",
       "\n",
       "                  user_id  \n",
       "0  ymlnR8UeFvB4FZL56tCZsA  \n",
       "1  9pSSL6X6lFpY3FCRLEH3og  \n",
       "2  CEtidlXNyQzgJSdF1ubPFw  \n",
       "3  cZVQGCZ_fHtTdfiyGVJPdg  \n",
       "4  li2cBZl60vgqihDJJG7jeA  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the feature variables, here is the text of the review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the values of the column that contains review text data, save to variable named \"documents\"\n",
    "\n",
    "documents = df['text'].values\n",
    "#here.values makes result numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect the documents , e.g. check the size, take a peek at elements of the numpy array\n",
    "documents.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(365550,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"My husband and I came out to Vegas for a mini vacation. Along the way he wanted to try a good steak dinner and boy we found it! \\r\\n\\r\\nI ordered the bone out ribeye and my husband ordered the Japanese Wagyu. Side dishes were the mushrooms and steak fries. 2 bottles of Syrah for drinks and banana cream pie for dessert. \\r\\n\\r\\nEveryone from the hostess to the bussers and servers were nothing short of gracious. Our server was John and he was outstanding with his wine recommendations and overall service. \\r\\n\\r\\nOur steaks were cooked perfectly, our glasses were never empty. Definitely an experience to remember. Delmonico's will be a destination for us every time we come to the city.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the target variable(any categorical variable that may be meaningful)\n",
    "\n",
    "Here, I am interested in perfect(5 stars) and inperfect(1-4 stars)rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False,  True, False, False, False, False,  True,\n",
       "        True])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a column and take the value, save to a variable named \"target\"\n",
    "df['favorable'] = df['stars'] >4\n",
    "target = df['favorable'].values\n",
    "target[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49467377923676653"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check some statistics of the target variable\n",
    "target.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4999716305675566"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(365550,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(365550,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training dataset and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20.0\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print (sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documents is x, target is y\n",
    "#Now split the data to training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split to documents_train, documents_test, target_train, target_test\n",
    "documents_train, documents_test, target_train, target_test = train_test_split(\n",
    "    documents,\n",
    "    target,\n",
    "    test_size = 0.8,\n",
    "    random_state = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get NLP representation of the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TfidfVectorizer and name it vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words = 'english', max_features = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with the training data\n",
    "vectors_train = vectorizer.fit_transform(documents_train).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the vocab of the Tfidf\n",
    "words = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73110, 5000)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trained model to transform the test data\n",
    "vectors_test = vectorizer.transform(documents_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(292440, 5000)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similar review search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will need these helper methods pretty soon\n",
    "def get_top_values(lst, n, labels):\n",
    "    '''\n",
    "    INPUT: LIST, INTEGER, LIST\n",
    "    OUTPUT: LIST\n",
    "    \n",
    "    Given a list of values, find the indices with highest n values.\n",
    "    Return the labels for each of these indices.\n",
    "    \n",
    "    e.g.\n",
    "    lst = [7, 3, 2, 4, 1]\n",
    "    n = 2\n",
    "    labels = ['cat', 'dog', 'mouse', 'pig', 'rabbit']\n",
    "    output:['cat', 'pig']\n",
    "    '''\n",
    "    return[labels[i] for i in np.argsort(lst)[::-1][:n]] #np.argsort by default sorts values in ascending order\n",
    "\n",
    "def get_bottom_values(lst, n, labels):\n",
    "    '''\n",
    "    INPUT: LIST, INTEGER, LIST\n",
    "    OUTPUT: LIST\n",
    "    \n",
    "    Given a list of values, find the indices with the lowest n values.\n",
    "    Return the labels for each of these indices.\n",
    "    \n",
    "    e.g.\n",
    "    lst = [7, 3, 2, 4, 1]\n",
    "    n = 2\n",
    "    labels = ['cat', 'dog', 'mouse', 'pig', 'rabbit']\n",
    "    output:['dog', 'mouse']\n",
    "    '''\n",
    "    return[labels[i] for i in np.argsort(lst)[:n]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use cosing similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antiques galore with great hospitality everything you'ld expect from an old school diner and more!   The staff here is extremely friendly and make sure you are well taken care of during your visit.  \r\n",
      "\r\n",
      "Seems like the majority of costumers here are working class mixed with retirees and definitely regulars to this establishment.  All the decor takes you back to a time definitely not forgetten here from the 1950's telephone to the early 80's Polaroid camera the window booths have vintage conversation starters galore.\r\n",
      "\r\n",
      "The food is delicious and appropriately prices on my first visit I had Curtis' Haystack ( biscuits and gravy topped with hashbrowns eggs and bacon) and it was a full meal for sure so being your best appetite for that one 4.25/5 \r\n",
      "\r\n",
      "Today I had the French Toast Special and the French Toast was prepared perfectly a nice buttery flavor and disappeared quickly. 2 eggs over medium and bacon completed the meal. 4.5/5.\r\n",
      "\r\n",
      "So if you are looking for a nice relaxing breakfast /lunch spot with great service and delicious food look no further than Lou's Diner the Diner that time forgot.\n",
      "[\"Antiques galore with great hospitality everything you'ld expect from an old school diner and more!   The staff here is extremely friendly and make sure you are well taken care of during your visit.  \\r\\n\\r\\nSeems like the majority of costumers here are working class mixed with retirees and definitely regulars to this establishment.  All the decor takes you back to a time definitely not forgetten here from the 1950's telephone to the early 80's Polaroid camera the window booths have vintage conversation starters galore.\\r\\n\\r\\nThe food is delicious and appropriately prices on my first visit I had Curtis' Haystack ( biscuits and gravy topped with hashbrowns eggs and bacon) and it was a full meal for sure so being your best appetite for that one 4.25/5 \\r\\n\\r\\nToday I had the French Toast Special and the French Toast was prepared perfectly a nice buttery flavor and disappeared quickly. 2 eggs over medium and bacon completed the meal. 4.5/5.\\r\\n\\r\\nSo if you are looking for a nice relaxing breakfast /lunch spot with great service and delicious food look no further than Lou's Diner the Diner that time forgot.\"]\n"
     ]
    }
   ],
   "source": [
    "# Draw an arbitrary review from test(unseen in training) documents\n",
    "some_random_number = 42\n",
    "search_query = documents_test[some_random_number]\n",
    "search_queries = [search_query] #Need to be put into a list - like format\n",
    "print(search_query)\n",
    "print(search_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the drawn review(s) to vector(s)\n",
    "vector_search_queries = vectorizer.transform(search_queries).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the similarity score(s) between vestor(s) and training vectors\n",
    "similarity_scores = cosine_similarity(vector_search_queries, vectors_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's find top 5 similar reviews\n",
    "n = 5\n",
    "returned_reviews= get_top_values(similarity_scores[0], n, documents_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our search query:\n",
      "Antiques galore with great hospitality everything you'ld expect from an old school diner and more!   The staff here is extremely friendly and make sure you are well taken care of during your visit.  \r\n",
      "\r\n",
      "Seems like the majority of costumers here are working class mixed with retirees and definitely regulars to this establishment.  All the decor takes you back to a time definitely not forgetten here from the 1950's telephone to the early 80's Polaroid camera the window booths have vintage conversation starters galore.\r\n",
      "\r\n",
      "The food is delicious and appropriately prices on my first visit I had Curtis' Haystack ( biscuits and gravy topped with hashbrowns eggs and bacon) and it was a full meal for sure so being your best appetite for that one 4.25/5 \r\n",
      "\r\n",
      "Today I had the French Toast Special and the French Toast was prepared perfectly a nice buttery flavor and disappeared quickly. 2 eggs over medium and bacon completed the meal. 4.5/5.\r\n",
      "\r\n",
      "So if you are looking for a nice relaxing breakfast /lunch spot with great service and delicious food look no further than Lou's Diner the Diner that time forgot.\n"
     ]
    }
   ],
   "source": [
    "print('Our search query:')\n",
    "print(search_queries[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query\n",
      "Antiques galore with great hospitality everything you'ld expect from an old school diner and more!   The staff here is extremely friendly and make sure you are well taken care of during your visit.  \r\n",
      "\r\n",
      "Seems like the majority of costumers here are working class mixed with retirees and definitely regulars to this establishment.  All the decor takes you back to a time definitely not forgetten here from the 1950's telephone to the early 80's Polaroid camera the window booths have vintage conversation starters galore.\r\n",
      "\r\n",
      "The food is delicious and appropriately prices on my first visit I had Curtis' Haystack ( biscuits and gravy topped with hashbrowns eggs and bacon) and it was a full meal for sure so being your best appetite for that one 4.25/5 \r\n",
      "\r\n",
      "Today I had the French Toast Special and the French Toast was prepared perfectly a nice buttery flavor and disappeared quickly. 2 eggs over medium and bacon completed the meal. 4.5/5.\r\n",
      "\r\n",
      "So if you are looking for a nice relaxing breakfast /lunch spot with great service and delicious food look no further than Lou's Diner the Diner that time forgot.\n",
      "\n",
      "\n",
      "Most 5 similary reviews:\n",
      "#0:\n",
      "Nice diner decore. Food is cheap and tastes pretty good, like what you would expect for a diner. They only had two waiters working and the service was not perhaps the fastest one.\n",
      "#1:\n",
      "This is great spot for breakfast if you like that diner feel   Food and service was wonderful on my visit\n",
      "#2:\n",
      "Great service, delicious food. Can't go wrong with this place! We ordered the Steak & Eggs with house fries and toast... Eggs Benedict with bacon... Corn beef hash... Sausage, biscuits n gravy, Greek salad & last but not least French toast. There were a few of us!  ALL of what we ordered was delicious!\n",
      "#3:\n",
      "Located on the outskirts of Downtown Las Vegas, this little diner packs a massive punch on flavor. They have the classic diner menu with breakfast and lunch items. I always go for the  make your own scramble breakfast plate. My go-to creation includes: chorizo, all the veggies, pepperjack cheese, avocado and salsa. It comes with their country potatoes and a side of toast. Whenever we have time  we also get the made to order biscuits and gravy. If you're looking for a filling meal at at a great price then definitely come to this spot.\n",
      "#4:\n",
      "Great food and the Service was GREAT. We had a very nice diner and drinks. Was recommended by freind andwewill go back\n"
     ]
    }
   ],
   "source": [
    "print('query')\n",
    "print(search_query)\n",
    "\n",
    "print('\\n\\nMost %s similary reviews:' %n)\n",
    "for i, review in enumerate(returned_reviews):\n",
    "    print('#%s:' %i)\n",
    "    print(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The results really make sense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying positive/negative review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive-Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a Naive-Bayes Classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model_nb = MultinomialNB()\n",
    "model_nb.fit(vectors_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.820093010532075"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get score for training set\n",
    "model_nb.score(vectors_train, target_train) # accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8120093010532075"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get score for testing set\n",
    "model_nb.score(vectors_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a Logistic Regression Classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model_lrc = LogisticRegression()\n",
    "model_lrc.fit(vectors_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8515524552044864"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get score for training set\n",
    "model_lrc.score(vectors_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.833552181644098"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get score for testing set\n",
    "model_lrc.score(vectors_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are the key features(words) that make the positive prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amazing',\n",
       " 'best',\n",
       " 'delicious',\n",
       " 'awesome',\n",
       " 'incredible',\n",
       " 'perfect',\n",
       " 'perfection',\n",
       " 'fantastic',\n",
       " 'thank',\n",
       " 'excellent',\n",
       " 'great',\n",
       " 'highly',\n",
       " 'love',\n",
       " 'die',\n",
       " 'heaven',\n",
       " 'regret',\n",
       " 'favorite',\n",
       " 'perfectly',\n",
       " 'outstanding',\n",
       " 'bomb']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's find out by ranking\n",
    "n = 20\n",
    "get_top_values(model_lrc.coef_[0], n, words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### All the positive words, people like to use amazing to express."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are the key features(words) that make the negative prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['worst',\n",
       " 'ok',\n",
       " 'horrible',\n",
       " 'rude',\n",
       " 'slow',\n",
       " 'disappointing',\n",
       " 'terrible',\n",
       " 'mediocre',\n",
       " 'okay',\n",
       " 'bland',\n",
       " 'reason',\n",
       " 'decent',\n",
       " 'poor',\n",
       " 'lacking',\n",
       " 'average',\n",
       " 'meh',\n",
       " 'wasn',\n",
       " 'worse',\n",
       " 'overall',\n",
       " 'unfortunately']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's find out by ranking\n",
    "n = 20\n",
    "get_bottom_values(model_lrc.coef_[0], n, words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The worst is the most straightforward word to express"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=20, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=10, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model_rfc = RandomForestClassifier(max_depth = 20,\n",
    "                                   n_estimators = 50,\n",
    "                                   min_samples_leaf = 10,\n",
    "                                   n_jobs = -1)\n",
    "\n",
    "model_rfc.fit(vectors_train, target_train)                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7993708111065517"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get score for training set\n",
    "model_rfc.score(vectors_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7853132266447819"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get score for testing set\n",
    "model_rfc.score(vectors_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find out the important features in RFC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amazing',\n",
       " 'delicious',\n",
       " 'best',\n",
       " 'ok',\n",
       " 'love',\n",
       " 'bad',\n",
       " 'minutes',\n",
       " 'didn',\n",
       " 'great',\n",
       " 'awesome',\n",
       " 'definitely',\n",
       " 'wasn',\n",
       " 'vegas',\n",
       " 'place',\n",
       " 'favorite',\n",
       " 'worst',\n",
       " 'friendly',\n",
       " 'terrible',\n",
       " 'rude',\n",
       " 'said']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 20\n",
    "get_top_values(model_rfc.feature_importances_, n, words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use cross validation to evaluate the classifiers\n",
    "[sklearn cross validation](http://scikit-learn.org/stable/modules/cross_validation.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8349176 , 0.82383916, 0.82916154, 0.83256959, 0.83585254])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_scores = cross_val_score(model_lrc,\n",
    "                           vectors_train,\n",
    "                           target_train,\n",
    "                           cv=5,\n",
    "                           scoring ='accuracy')\n",
    "cv_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use grid search to find best predictable classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "\n",
      "{'C': 100, 'penalty': 'l2'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "0.518 (+/-0.005) for {'C': 0.1, 'penalty': 'l1'}\n",
      "0.718 (+/-0.085) for {'C': 100, 'penalty': 'l1'}\n",
      "0.644 (+/-0.046) for {'C': 0.1, 'penalty': 'l2'}\n",
      "0.720 (+/-0.079) for {'C': 100, 'penalty': 'l2'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.74      0.78      0.76    147599\n",
      "        True       0.76      0.73      0.74    144841\n",
      "\n",
      "   micro avg       0.75      0.75      0.75    292440\n",
      "   macro avg       0.75      0.75      0.75    292440\n",
      "weighted avg       0.75      0.75      0.75    292440\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "param_grid = [{'penalty':['l1'], 'C':[0.1, 100]},\n",
    "              {'penalty':['l2'], 'C':[0.1, 100]}]\n",
    "\n",
    "scores = ['accuracy']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score + \"\\n\\n\")\n",
    "    clf = GridSearchCV(LogisticRegression(),\n",
    "                       param_grid,\n",
    "                       cv=5,\n",
    "                       scoring=score)\n",
    "    clf.fit(vectors_train[:500,:], target_train[:500])\n",
    "    print(\"Best parameters set found on development set:\\n\\n\")\n",
    "    print(clf.best_params_)\n",
    "    print(\"\\nGrid scores on development set:\\n\\n\")\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    \n",
    "    print(\"\\nDetailed classification report:\\n\")\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print(\"\\n\")\n",
    "    y_true, y_pred = target_test, clf.predict(vectors_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
